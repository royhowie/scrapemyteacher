scrapemyteacher
===============
This is a web scraper written in Python to automatically collect data for an entire college and graph it with d3.

*How do **I** use it?*

Go to [this page](http://www.ratemyprofessors.com/search.jsp) and search for your school. For example, if you go to UM, you would type "University of Miami" (without the quotes!) and hit enter. Don't select any of the suggested results.

This will load a page that says "Showing 1-20 of XXXX results". The link should look like this:

  # http://www.ratemyprofessors.com/search.jsp?query=university+of+miami&offset=
  
If it doesn't have `&offset=`, append just that. Then, navigate to `scrape.py` and, on line 6, change `template = ...` to `template = "YOUR_LINK_IN_QUOTES"`.

Now (this part is super important), you need to take that number, `XXXX`, and divide it by 20 and round up to the nearest whole number. Change line 11 to:

  for i in xrange(0, THAT_XXXX_NUMBER_DIVIDED_BY_20_ROUNDED_UP):
  # write the actual number, not THAT_XXXX_NUMBER_DIVIDED_BY_20_ROUNDED_UP
  # as an example, it was 104 for when I scraped the UM data.

In the near future, I'll make it so you can pass the school id via an argument, when running the script. But that's soonâ„¢.

Now, you'll need to run this file. If you have a windows computer, you can't be saved. Figure it out.

If you're on max/linux, then you're bueno. Let's get cooking. You'll need to have python installed, along with the requests library.

"But how do I checked this?" Open up terminal (hit command space, then type "terminal", then hit enter). Type `python` and hit enter. If you have python, you'll see something like:

  Python 2.7.5 (default, Mar  9 2014, 22:15:05) 
  [GCC 4.2.1 Compatible Apple LLVM 5.0 (clang-500.0.68)] on darwin
  Type "help", "copyright", "credits" or "license" for more information.
  
Hit <kbd>control-D</kbd>
  
If not, there will be some error message. Macs have python installed by default. If you don't have python installed, visit [python.org](https://www.python.org) and follow the installation instructions.

Now, you need to [install `requests`](http://docs.python-requests.org/en/latest/user/install/), so the script can scrape. This is rather easy, provided you have python installed.

  pip install requests
  # OR
  easy_install requests

Pick your poison.

---

If you don't know how to use terminal:

Once you've done that, you're about set to go. Open up a new tab in terminal and type in `python`, followed by a space. By now, you should have downloaded all the files in this repository. As long as they are in the same folder, you should be fine. Drag and drop the `scrape.py` file onto terminal. You should seem something like

  $ python /Users/royhowie/code/repo/scrapemyteacher/scrape.py
  
Hit enter. This will collect all the teacher IDs it needs to find. This part of the web scraping is rather quick.

---

Once that file has finished executing, you need to run `getteachers.py`. You don't need to edit this file. Depending on the size of your school, this will have to do upwards of a few thousands of requests. The file did 2077 page requests for UM, which took about 20 minutes. Your time may vary (internet speed, etc.).

After that `getteachers.py` has finished running, find `data.txt` and make sure it has the appropriate data. DO NOT EDIT THIS FILE.

If the data is bueno, you can open `scatterplot.html` and feast your eyes.

I'm currently in the process of fixing my website, but if you want me to host your school's data, send me a note, along with the appropriate data files.
